{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee7fad1-7d3f-46ff-87a9-cf7603265f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:14:41.374781Z",
     "iopub.status.busy": "2025-10-17T09:14:41.374089Z",
     "iopub.status.idle": "2025-10-17T09:14:51.954900Z",
     "shell.execute_reply": "2025-10-17T09:14:51.953829Z",
     "shell.execute_reply.started": "2025-10-17T09:14:41.374745Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import onnx\n",
    "import random\n",
    "import gc\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType, QuantFormat\n",
    "from onnxruntime.quantization.calibrate import CalibrationMethod\n",
    "\n",
    "import time\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "!python3 -m onnxruntime.quantization.preprocess --input model_efficientnetv2s_11.onnx --output model_efficientnetv2s_11-infer.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9eb09a-04ea-45d0-86c3-5bc72db2b7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:14:54.560256Z",
     "iopub.status.busy": "2025-10-17T09:14:54.559278Z",
     "iopub.status.idle": "2025-10-17T09:14:54.599760Z",
     "shell.execute_reply": "2025-10-17T09:14:54.598830Z",
     "shell.execute_reply.started": "2025-10-17T09:14:54.560220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape(3,1,1)\n",
    "STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(3,1,1)\n",
    "\n",
    "# Preprocessing function for the images\n",
    "def preprocess(p):\n",
    "    img = Image.open(p).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n",
    "    x = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    x = (x.transpose(2,0,1) - MEAN) / STD\n",
    "    img.close()\n",
    "    return x[np.newaxis, :]  # NCHW\n",
    "\n",
    "# Calibration reader class with balanced class sampling\n",
    "class RandomSampleCalibrationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, img_dir, model_path, batch_size=1, sample_size=1000, seed=42, csv_path=None):\n",
    "        sess = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "        self.input_name = sess.get_inputs()[0].name\n",
    "        del sess\n",
    "        gc.collect()\n",
    "        \n",
    "        random.seed(seed)\n",
    "        \n",
    "        if csv_path:\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"Warning: CSV file not found at '{csv_path}'\")\n",
    "                print(\"Falling back to directory-based sampling\")\n",
    "            else:\n",
    "                try:\n",
    "                    # Load paths from CSV with balanced sampling\n",
    "                    # Try semicolon separator first (common in European locales), then comma\n",
    "                    try:\n",
    "                        df = pd.read_csv(csv_path, sep=',')\n",
    "                    except:\n",
    "                        df = pd.read_csv(csv_path)\n",
    "                    \n",
    "                    # Ensure required columns exist\n",
    "                    if 'parking' not in df.columns or 'path' not in df.columns:\n",
    "                        raise ValueError(f\"CSV must have 'parking' and 'path' columns. Found: {df.columns.tolist()}\")\n",
    "                    \n",
    "                    # Group by class\n",
    "                    classes = df['parking'].unique()\n",
    "                    samples_per_class = sample_size // len(classes)\n",
    "                    \n",
    "                    balanced_paths = []\n",
    "                    class_counts = {}  # Track counts during sampling\n",
    "                    \n",
    "                    for cls in classes:\n",
    "                        cls_df = df[df['parking'] == cls]\n",
    "                        n_samples = min(len(cls_df), samples_per_class)\n",
    "                        sampled = cls_df.sample(n=n_samples, random_state=seed)\n",
    "                        sampled_paths = sampled['path'].tolist()\n",
    "                        balanced_paths.extend(sampled_paths)\n",
    "                        class_counts[cls] = len(sampled_paths)\n",
    "                    \n",
    "                    # Shuffle the balanced dataset\n",
    "                    random.shuffle(balanced_paths)\n",
    "                    self.paths = balanced_paths[:sample_size]\n",
    "                    \n",
    "                    print(f\"Loaded {len(self.paths)} balanced samples from CSV: {csv_path}\")\n",
    "                    for cls in classes:\n",
    "                        print(f\"  Class '{cls}': {class_counts[cls]} samples\")\n",
    "                    \n",
    "                    # Successfully loaded from CSV, skip fallback\n",
    "                    self.batch_size = batch_size\n",
    "                    self.idx = 0\n",
    "                    return\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading CSV: {e}\")\n",
    "                    print(\"Falling back to directory-based sampling\")\n",
    "        \n",
    "        # Fallback to directory-based balanced sampling\n",
    "        # Try to detect class subdirectories\n",
    "        subdirs = [d for d in os.listdir(img_dir) if os.path.isdir(os.path.join(img_dir, d))]\n",
    "        \n",
    "        if subdirs and len(subdirs) > 1:\n",
    "            # Sample from subdirectories (assuming they represent classes)\n",
    "            samples_per_class = sample_size // len(subdirs)\n",
    "            balanced_paths = []\n",
    "            \n",
    "            for subdir in subdirs:\n",
    "                subdir_path = os.path.join(img_dir, subdir)\n",
    "                class_paths = sorted(sum([glob.glob(os.path.join(subdir_path, f\"*{ext}\")) \n",
    "                                         for ext in [\".jpg\",\".jpeg\",\".png\"]], []))\n",
    "                n_samples = min(len(class_paths), samples_per_class)\n",
    "                balanced_paths.extend(random.sample(class_paths, n_samples))\n",
    "            \n",
    "            random.shuffle(balanced_paths)\n",
    "            self.paths = balanced_paths[:sample_size]\n",
    "            print(f\"Loaded {len(self.paths)} balanced samples from {len(subdirs)} class directories\")\n",
    "        else:\n",
    "            # No class structure detected, use random sampling\n",
    "            self.paths = sorted(sum([glob.glob(os.path.join(img_dir, f\"*{ext}\")) \n",
    "                                    for ext in [\".jpg\",\".jpeg\",\".png\"]], []))\n",
    "            self.paths = random.sample(self.paths, min(len(self.paths), sample_size))\n",
    "            print(f\"Warning: No class structure detected. Using {len(self.paths)} random samples\")\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.idx = 0\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.idx >= len(self.paths):\n",
    "            return None\n",
    "        \n",
    "        batch = []\n",
    "        while len(batch) < self.batch_size and self.idx < len(self.paths):\n",
    "            img_data = preprocess(self.paths[self.idx])\n",
    "            self.idx += 1\n",
    "            if img_data is not None:\n",
    "                batch.append(img_data)\n",
    "        \n",
    "        if not batch:\n",
    "            return None\n",
    "            \n",
    "        data = np.concatenate(batch, axis=0)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if self.idx % 50 == 0:\n",
    "            print(f\"Processed {self.idx}/{len(self.paths)} calibration images\")\n",
    "        \n",
    "        return {self.input_name: data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "050f5826-bb45-4eb6-a548-ddac6f1d1577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:09:37.847488Z",
     "iopub.status.busy": "2025-10-17T09:09:37.846441Z",
     "iopub.status.idle": "2025-10-17T09:10:17.207900Z",
     "shell.execute_reply": "2025-10-17T09:10:17.207071Z",
     "shell.execute_reply.started": "2025-10-17T09:09:37.847445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 balanced samples from CSV: data/parking_label_train.csv\n",
      "  Class 'inside': 100 samples\n",
      "  Class 'hard_to_say': 100 samples\n",
      "  Class 'outside': 100 samples\n",
      "Processed 300/300 calibration images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model = \"model_efficientnetv2s_11-infer.onnx\"          \n",
    "int8_model = \"efficientnetv2s_11_int8_qdq.onnx\"      \n",
    "calib_dir  = \"/home/jupyter/mnt/datasets/scooters_data/\"\n",
    "calib_csv = \"data/parking_label_train.csv\"\n",
    "\n",
    "dr = RandomSampleCalibrationDataReader(calib_dir, fp32_model, batch_size=24, sample_size=300, seed=42, csv_path=calib_csv)\n",
    "\n",
    "# Perform the quantization\n",
    "quantize_static(\n",
    "        model_input=fp32_model,\n",
    "        model_output=int8_model,\n",
    "        calibration_data_reader=dr,\n",
    "        calibrate_method=CalibrationMethod.MinMax,  # You can also try Entropy or MinMax\n",
    "        per_channel=False, # because opset should be 11, not 13<\n",
    "        weight_type=QuantType.QInt8,                    \n",
    "        activation_type=QuantType.QUInt8,               \n",
    "        reduce_range=False,\n",
    "        quant_format=QuantFormat.QDQ,\n",
    "        op_types_to_quantize=[\"Conv\", \"MatMul\"]\n",
    "    )\n",
    "# Cleanup and validate\n",
    "del dr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4bdc1c0-bc9f-4f43-bbfe-cb7fc07b4ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:10:21.645796Z",
     "iopub.status.busy": "2025-10-17T09:10:21.645014Z",
     "iopub.status.idle": "2025-10-17T09:10:21.771670Z",
     "shell.execute_reply": "2025-10-17T09:10:21.770836Z",
     "shell.execute_reply.started": "2025-10-17T09:10:21.645760Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Quantized model saved and validated: efficientnetv2s_11_int8_qdq.onnx\n"
     ]
    }
   ],
   "source": [
    "# Validate model (skip strict opset checks for quantized models)\n",
    "try:\n",
    "    model = onnx.load(int8_model)\n",
    "    onnx.checker.check_model(model, skip_opset_compatibility_check=True)\n",
    "    print(\"✓ Quantized model saved and validated:\", int8_model)\n",
    "except Exception as e:\n",
    "    # Model might be valid but checker is too strict - verify it loads in ONNX Runtime\n",
    "    print(f\"Note: ONNX checker warning (can be ignored): {e}\")\n",
    "    try:\n",
    "        sess = ort.InferenceSession(int8_model, providers=[\"CPUExecutionProvider\"])\n",
    "        print(\"✓ Quantized model saved and loadable:\", int8_model)\n",
    "        del sess\n",
    "    except Exception as load_error:\n",
    "        print(f\"✗ Error: Model cannot be loaded: {load_error}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae3a3a-8303-4112-a5d8-1d033af0b2a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6520c90e-126a-454e-95f5-5e12ceacc6c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:10:29.359422Z",
     "iopub.status.busy": "2025-10-17T09:10:29.358215Z",
     "iopub.status.idle": "2025-10-17T09:10:30.906875Z",
     "shell.execute_reply": "2025-10-17T09:10:30.906033Z",
     "shell.execute_reply.started": "2025-10-17T09:10:29.359382Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 ms median: 18.711328506469727\n",
      "INT8 ms median: 22.83501625061035\n",
      "Cosine sim logits: 0.99468005\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/home/jupyter/mnt/datasets/scooters_data/b698239449d24ded86cace09b20841b7.jpeg\"\n",
    "x = preprocess(img_path)\n",
    "\n",
    "def run(model):\n",
    "    sess = ort.InferenceSession(model, providers=[\"CPUExecutionProvider\"])\n",
    "    name_in  = sess.get_inputs()[0].name\n",
    "    name_out = sess.get_outputs()[0].name\n",
    "    for _ in range(5): sess.run([name_out], {name_in: x})\n",
    "    t = []\n",
    "    for _ in range(20):\n",
    "        s = time.time(); y = sess.run([name_out], {name_in: x}); t.append(time.time()-s)\n",
    "    return np.array(t), y[0]\n",
    "\n",
    "t_fp32, y_fp32 = run(\"model_efficientnetv2s_11-infer.onnx\")\n",
    "t_int8, y_int8 = run(\"efficientnetv2s_11_int8_qdq.onnx\")\n",
    "\n",
    "print(\"FP32 ms median:\", np.median(t_fp32)*1000)\n",
    "print(\"INT8 ms median:\", np.median(t_int8)*1000)\n",
    "print(\"Cosine sim logits:\", (y_fp32.flatten()@y_int8.flatten())/(np.linalg.norm(y_fp32.flatten())*np.linalg.norm(y_int8.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135935f2-82fb-440f-bae2-e8a856f8296a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:15:05.382779Z",
     "iopub.status.busy": "2025-10-17T09:15:05.381638Z",
     "iopub.status.idle": "2025-10-17T09:15:05.397325Z",
     "shell.execute_reply": "2025-10-17T09:15:05.396507Z",
     "shell.execute_reply.started": "2025-10-17T09:15:05.382743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_PATH= \"data/parking_label_test.csv\"\n",
    "\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 3\n",
    "N_SAMPLES = 8978\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"hard_to_say\": 0,\n",
    "    \"inside\": 1,\n",
    "    \"outside\": 2\n",
    "}\n",
    "\n",
    "def preprocess_image_from_path(img_path, img_size=IMG_SIZE):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = img.resize((img_size, img_size))\n",
    "        img_array = np.array(img).astype(np.float32) / 255.0\n",
    "        img_array = np.transpose(img_array, (2, 0, 1))\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"[Ошибка] Не удалось обработать {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def predict_image(img_array):\n",
    "    outputs = session.run([output_name], {input_name: img_array})\n",
    "    preds = outputs[0]\n",
    "    predicted_class = int(np.argmax(preds, axis=1)[0])\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06553b8d-908e-4aa5-8f34-e1399b3467cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:10:50.153759Z",
     "iopub.status.busy": "2025-10-17T09:10:50.152567Z",
     "iopub.status.idle": "2025-10-17T09:12:40.601128Z",
     "shell.execute_reply": "2025-10-17T09:12:40.599356Z",
     "shell.execute_reply.started": "2025-10-17T09:10:50.153712Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка изображений:  26%|██▋       | 2372/8978 [00:46<02:10, 50.79it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4325/3200725623.py\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Process results as they complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Обработка изображений\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtrue_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4325/3200725623.py\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mper_class_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_WORKERS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Submit all tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model_efficientnetv2s\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "ONNX_PATH = \"model_efficientnetv2s_11.onnx\"\n",
    "N_WORKERS = 30  # Adjust based on your CPU cores\n",
    "\n",
    "session = ort.InferenceSession(ONNX_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.iloc[:N_SAMPLES, :]\n",
    "df = df.rename(columns={df.columns[0]: \"parking\", df.columns[1]: \"path\"})\n",
    "\n",
    "def process_row(row):\n",
    "    \"\"\"Process a single row and return results\"\"\"\n",
    "    label_str = str(row[\"parking\"]).strip().lower()\n",
    "    if label_str not in LABEL_MAP:\n",
    "        return None, None, f\"{label_str=} not in LABEL_MAP\"\n",
    "    \n",
    "    true_label = LABEL_MAP[label_str]\n",
    "    img_path = row[\"path\"]\n",
    "    \n",
    "    img_array = preprocess_image_from_path(img_path)\n",
    "    if img_array is None:\n",
    "        return None, None, f\"{img_path} preprocessing failed\"\n",
    "    \n",
    "    pred = predict_image(img_array)\n",
    "    return true_label, pred, None\n",
    "\n",
    "# Parallel processing\n",
    "correct = 0\n",
    "total = 0\n",
    "per_class_correct = {0: 0, 1: 0, 2: 0}\n",
    "per_class_total = {0: 0, 1: 0, 2: 0}\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {executor.submit(process_row, row): idx for idx, row in df.iterrows()}\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Обработка изображений\"):\n",
    "        true_label, pred, error = future.result()\n",
    "        \n",
    "        if error:\n",
    "            print(error)\n",
    "            continue\n",
    "        \n",
    "        if pred == true_label:\n",
    "            correct += 1\n",
    "            per_class_correct[true_label] += 1\n",
    "        per_class_total[true_label] += 1\n",
    "        total += 1\n",
    "\n",
    "accuracy = correct / total * 100 if total > 0 else 0\n",
    "print(\"\\n========= РЕЗУЛЬТАТ =========\")\n",
    "print(f\"Всего изображений: {total}\")\n",
    "print(f\"Общая точность: {accuracy:.2f}%\\n\")\n",
    "\n",
    "print(\"Точность по классам:\")\n",
    "for k, v in per_class_total.items():\n",
    "    if v > 0:\n",
    "        acc = per_class_correct[k] / v * 100\n",
    "        print(f\"Класс {k}: {acc:.2f}% ({per_class_correct[k]}/{v})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dfd5ee9-2543-4338-8ab4-7a5b9be0fccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T09:15:10.625199Z",
     "iopub.status.busy": "2025-10-17T09:15:10.624008Z",
     "iopub.status.idle": "2025-10-17T09:17:03.202814Z",
     "shell.execute_reply": "2025-10-17T09:17:03.201609Z",
     "shell.execute_reply.started": "2025-10-17T09:15:10.625165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка изображений: 100%|██████████| 8978/8978 [01:51<00:00, 80.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= РЕЗУЛЬТАТ =========\n",
      "Всего изображений: 8978\n",
      "Общая точность: 65.35%\n",
      "\n",
      "Точность по классам:\n",
      "Класс 0: 27.39% (582/2125)\n",
      "Класс 1: 90.30% (4963/5496)\n",
      "Класс 2: 23.73% (322/1357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# efficientnetv2s_int8_qdq\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "ONNX_PATH = \"efficientnetv2s_11_int8_qdq.onnx\"\n",
    "N_WORKERS = 30  # Adjust based on your CPU cores\n",
    "\n",
    "session = ort.InferenceSession(ONNX_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.iloc[:N_SAMPLES, :]\n",
    "df = df.rename(columns={df.columns[0]: \"parking\", df.columns[1]: \"path\"})\n",
    "\n",
    "def process_row(row):\n",
    "    \"\"\"Process a single row and return results\"\"\"\n",
    "    label_str = str(row[\"parking\"]).strip().lower()\n",
    "    if label_str not in LABEL_MAP:\n",
    "        return None, None, f\"{label_str=} not in LABEL_MAP\"\n",
    "    \n",
    "    true_label = LABEL_MAP[label_str]\n",
    "    img_path = row[\"path\"]\n",
    "    \n",
    "    img_array = preprocess_image_from_path(img_path)\n",
    "    if img_array is None:\n",
    "        return None, None, f\"{img_path} preprocessing failed\"\n",
    "    \n",
    "    pred = predict_image(img_array)\n",
    "    return true_label, pred, None\n",
    "\n",
    "# Parallel processing\n",
    "correct = 0\n",
    "total = 0\n",
    "per_class_correct = {0: 0, 1: 0, 2: 0}\n",
    "per_class_total = {0: 0, 1: 0, 2: 0}\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {executor.submit(process_row, row): idx for idx, row in df.iterrows()}\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Обработка изображений\"):\n",
    "        true_label, pred, error = future.result()\n",
    "        \n",
    "        if error:\n",
    "            print(error)\n",
    "            continue\n",
    "        \n",
    "        if pred == true_label:\n",
    "            correct += 1\n",
    "            per_class_correct[true_label] += 1\n",
    "        per_class_total[true_label] += 1\n",
    "        total += 1\n",
    "\n",
    "accuracy = correct / total * 100 if total > 0 else 0\n",
    "print(\"\\n========= РЕЗУЛЬТАТ =========\")\n",
    "print(f\"Всего изображений: {total}\")\n",
    "print(f\"Общая точность: {accuracy:.2f}%\\n\")\n",
    "\n",
    "print(\"Точность по классам:\")\n",
    "for k, v in per_class_total.items():\n",
    "    if v > 0:\n",
    "        acc = per_class_correct[k] / v * 100\n",
    "        print(f\"Класс {k}: {acc:.2f}% ({per_class_correct[k]}/{v})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eeeb86-57c1-491a-ba1c-119e598cd05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
